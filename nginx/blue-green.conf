# =============================================================================
# NGINX BLUE-GREEN DEPLOYMENT CONFIGURATION
# =============================================================================
#
# This configuration enables zero-downtime deployments via blue-green strategy.
#
# Traffic Routing:
# - Default: Routes to BLUE environment
# - To switch: Edit active_backend in conf.d/active.conf and reload nginx
#
# Contract: CTR-DEPLOY-001
# =============================================================================

worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/json;

    # Logging format with correlation ID
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_request_id" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml application/json application/javascript;

    # ==========================================================================
    # UPSTREAM DEFINITIONS
    # ==========================================================================

    # Blue environment (primary)
    upstream inference_blue {
        server inference-blue:8003 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # Green environment (secondary/standby)
    upstream inference_green {
        server inference-green:8003 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # ==========================================================================
    # ACTIVE BACKEND MAPPING
    # ==========================================================================
    # This map determines which backend receives traffic
    # To switch: Change the default value and reload nginx
    # Production: Use conf.d/active.conf to override

    map $host $active_backend {
        default "inference_blue";
        # Uncomment to switch to green:
        # default "inference_green";
    }

    # Include dynamic configuration
    include /etc/nginx/conf.d/*.conf;

    # ==========================================================================
    # SERVER CONFIGURATION
    # ==========================================================================

    server {
        listen 80;
        server_name _;

        # Request ID propagation for distributed tracing
        set $request_id $http_x_request_id;
        if ($request_id = '') {
            set $request_id $request_id$connection$msec;
        }

        # Health check endpoint (for load balancer itself)
        location /health {
            access_log off;
            return 200 '{"status":"healthy","service":"nginx-lb"}';
            add_header Content-Type application/json;
        }

        # Status endpoint showing active backend
        location /lb-status {
            access_log off;
            return 200 '{"active_backend":"$active_backend","timestamp":"$time_iso8601"}';
            add_header Content-Type application/json;
        }

        # =======================================================================
        # API VERSION 1 ENDPOINTS
        # =======================================================================

        location /v1/ {
            # Dynamic backend selection based on active_backend variable
            set $backend $active_backend;

            # Route to appropriate upstream
            proxy_pass http://$backend;

            # Proxy headers
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Request-ID $request_id;
            proxy_set_header Connection "";

            # Timeouts
            proxy_connect_timeout 10s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;

            # Buffering
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;

            # Error handling
            proxy_next_upstream error timeout http_502 http_503 http_504;
            proxy_next_upstream_tries 2;
        }

        # Direct blue access (for testing)
        location /blue/ {
            rewrite ^/blue/(.*)$ /$1 break;
            proxy_pass http://inference_blue;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Request-ID $request_id;
            proxy_set_header Connection "";
        }

        # Direct green access (for testing)
        location /green/ {
            rewrite ^/green/(.*)$ /$1 break;
            proxy_pass http://inference_green;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Request-ID $request_id;
            proxy_set_header Connection "";
        }

        # Default route
        location / {
            return 404 '{"error":"not_found","message":"Use /v1/ for API endpoints"}';
            add_header Content-Type application/json;
        }
    }
}
