#!/usr/bin/env python3
"""
Penetration Test Preparation Checklist
=======================================

Sprint 4: SEC-30 - Penetration test preparation

This script validates security measures are in place before
conducting a penetration test. Run this before engaging
with external security testers.

Usage:
    python scripts/pentest_checklist.py
    python scripts/pentest_checklist.py --verbose
    python scripts/pentest_checklist.py --output report.json

Author: Trading Team
Date: 2026-01-17
"""

import argparse
import json
import os
import re
import subprocess
import sys
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any


@dataclass
class CheckResult:
    """Result of a security check."""
    name: str
    category: str
    passed: bool
    severity: str  # critical, high, medium, low, info
    message: str
    details: Optional[str] = None
    recommendation: Optional[str] = None


@dataclass
class PentestReport:
    """Complete penetration test preparation report."""
    timestamp: str
    total_checks: int = 0
    passed: int = 0
    failed: int = 0
    warnings: int = 0
    results: List[CheckResult] = field(default_factory=list)

    def add_result(self, result: CheckResult) -> None:
        self.results.append(result)
        self.total_checks += 1
        if result.passed:
            self.passed += 1
        elif result.severity in ('critical', 'high'):
            self.failed += 1
        else:
            self.warnings += 1

    @property
    def overall_status(self) -> str:
        if any(r.severity == 'critical' and not r.passed for r in self.results):
            return "CRITICAL_ISSUES"
        if any(r.severity == 'high' and not r.passed for r in self.results):
            return "HIGH_ISSUES"
        if self.failed > 0:
            return "ISSUES_FOUND"
        if self.warnings > 0:
            return "WARNINGS"
        return "READY"

    def to_dict(self) -> Dict[str, Any]:
        return {
            "timestamp": self.timestamp,
            "overall_status": self.overall_status,
            "summary": {
                "total_checks": self.total_checks,
                "passed": self.passed,
                "failed": self.failed,
                "warnings": self.warnings,
            },
            "results": [
                {
                    "name": r.name,
                    "category": r.category,
                    "passed": r.passed,
                    "severity": r.severity,
                    "message": r.message,
                    "details": r.details,
                    "recommendation": r.recommendation,
                }
                for r in self.results
            ],
        }


class PentestChecklist:
    """Security checklist validator for penetration test preparation."""

    def __init__(self, project_root: Path, verbose: bool = False):
        self.project_root = project_root
        self.verbose = verbose
        self.report = PentestReport(timestamp=datetime.utcnow().isoformat())

    def log(self, message: str) -> None:
        if self.verbose:
            print(f"  [DEBUG] {message}")

    def run_all_checks(self) -> PentestReport:
        """Run all security checks."""
        print("=" * 60)
        print("PENETRATION TEST PREPARATION CHECKLIST")
        print("=" * 60)
        print(f"Project: {self.project_root}")
        print(f"Time: {self.report.timestamp}")
        print()

        # Authentication & Authorization
        print("[1/7] Checking Authentication & Authorization...")
        self._check_auth_middleware()
        self._check_api_key_security()
        self._check_jwt_configuration()

        # Network Security
        print("[2/7] Checking Network Security...")
        self._check_cors_configuration()
        self._check_security_headers()
        self._check_https_enforcement()

        # Input Validation
        print("[3/7] Checking Input Validation...")
        self._check_request_size_limits()
        self._check_sql_injection_protection()
        self._check_command_injection_protection()

        # Secrets Management
        print("[4/7] Checking Secrets Management...")
        self._check_env_files()
        self._check_hardcoded_secrets()
        self._check_git_history()

        # API Security
        print("[5/7] Checking API Security...")
        self._check_swagger_protection()
        self._check_rate_limiting()
        self._check_error_handling()

        # Infrastructure Security
        print("[6/7] Checking Infrastructure Security...")
        self._check_docker_security()
        self._check_dependency_vulnerabilities()

        # Logging & Monitoring
        print("[7/7] Checking Logging & Monitoring...")
        self._check_audit_logging()
        self._check_security_monitoring()

        return self.report

    # =========================================================================
    # Authentication & Authorization Checks
    # =========================================================================

    def _check_auth_middleware(self) -> None:
        """Check if authentication middleware is properly configured."""
        auth_file = self.project_root / "services/inference_api/middleware/auth.py"

        if not auth_file.exists():
            self.report.add_result(CheckResult(
                name="Auth Middleware",
                category="Authentication",
                passed=False,
                severity="critical",
                message="Authentication middleware not found",
                recommendation="Create auth.py middleware for API authentication",
            ))
            return

        content = auth_file.read_text()

        # Check for proper implementation
        has_api_key = "API_KEY" in content or "api_key" in content
        has_bearer = "Bearer" in content or "bearer" in content
        has_validation = "verify" in content or "validate" in content

        if has_api_key and has_validation:
            self.report.add_result(CheckResult(
                name="Auth Middleware",
                category="Authentication",
                passed=True,
                severity="info",
                message="Authentication middleware is configured",
            ))
        else:
            self.report.add_result(CheckResult(
                name="Auth Middleware",
                category="Authentication",
                passed=False,
                severity="high",
                message="Authentication middleware may be incomplete",
                recommendation="Ensure API key validation is implemented",
            ))

    def _check_api_key_security(self) -> None:
        """Check API key security configuration."""
        # Check for minimum key length configuration
        auth_file = self.project_root / "services/inference_api/middleware/auth.py"

        if auth_file.exists():
            content = auth_file.read_text()
            has_key_validation = "len(" in content or "MIN_KEY_LENGTH" in content

            self.report.add_result(CheckResult(
                name="API Key Length Validation",
                category="Authentication",
                passed=has_key_validation,
                severity="medium" if not has_key_validation else "info",
                message="API key length validation " + ("present" if has_key_validation else "not found"),
                recommendation="Enforce minimum API key length (32+ characters)" if not has_key_validation else None,
            ))

    def _check_jwt_configuration(self) -> None:
        """Check JWT configuration if used."""
        # Search for JWT usage
        jwt_files = list(self.project_root.glob("**/*.py"))
        jwt_usage = False

        for f in jwt_files[:100]:  # Limit search
            try:
                if "jwt" in f.read_text().lower():
                    jwt_usage = True
                    break
            except:
                pass

        if jwt_usage:
            self.report.add_result(CheckResult(
                name="JWT Configuration",
                category="Authentication",
                passed=True,
                severity="info",
                message="JWT usage detected - ensure proper configuration",
                recommendation="Verify JWT secret strength, algorithm (RS256 preferred), and expiration",
            ))

    # =========================================================================
    # Network Security Checks
    # =========================================================================

    def _check_cors_configuration(self) -> None:
        """Check CORS configuration for security."""
        main_file = self.project_root / "services/inference_api/main.py"

        if not main_file.exists():
            self.report.add_result(CheckResult(
                name="CORS Configuration",
                category="Network Security",
                passed=False,
                severity="high",
                message="Main application file not found",
            ))
            return

        content = main_file.read_text()

        # Check for wildcard CORS
        if 'allow_origins=["*"]' in content or "allow_origins=['*']" in content:
            self.report.add_result(CheckResult(
                name="CORS Configuration",
                category="Network Security",
                passed=False,
                severity="critical",
                message="CORS allows all origins (*)",
                recommendation="Restrict CORS to specific trusted origins",
            ))
        elif "allow_origins=" in content:
            self.report.add_result(CheckResult(
                name="CORS Configuration",
                category="Network Security",
                passed=True,
                severity="info",
                message="CORS is configured with restricted origins",
            ))
        else:
            self.report.add_result(CheckResult(
                name="CORS Configuration",
                category="Network Security",
                passed=False,
                severity="medium",
                message="CORS configuration not found",
                recommendation="Configure CORS middleware with specific origins",
            ))

    def _check_security_headers(self) -> None:
        """Check security headers middleware."""
        headers_file = self.project_root / "services/inference_api/middleware/security_headers.py"

        required_headers = [
            "X-Content-Type-Options",
            "X-Frame-Options",
            "Strict-Transport-Security",
            "Content-Security-Policy",
            "X-XSS-Protection",
        ]

        if not headers_file.exists():
            self.report.add_result(CheckResult(
                name="Security Headers Middleware",
                category="Network Security",
                passed=False,
                severity="high",
                message="Security headers middleware not found",
                recommendation="Create security headers middleware with OWASP headers",
            ))
            return

        content = headers_file.read_text()
        missing_headers = [h for h in required_headers if h not in content]

        if not missing_headers:
            self.report.add_result(CheckResult(
                name="Security Headers Middleware",
                category="Network Security",
                passed=True,
                severity="info",
                message="All required security headers are configured",
            ))
        else:
            self.report.add_result(CheckResult(
                name="Security Headers Middleware",
                category="Network Security",
                passed=False,
                severity="high",
                message=f"Missing security headers: {', '.join(missing_headers)}",
                recommendation="Add missing headers to security middleware",
            ))

    def _check_https_enforcement(self) -> None:
        """Check HTTPS/TLS enforcement."""
        compose_file = self.project_root / "docker-compose.yml"

        if compose_file.exists():
            content = compose_file.read_text()
            has_https = "443" in content or "https" in content.lower() or "ssl" in content.lower()

            self.report.add_result(CheckResult(
                name="HTTPS Configuration",
                category="Network Security",
                passed=has_https,
                severity="high" if not has_https else "info",
                message="HTTPS/TLS " + ("configured" if has_https else "not explicitly configured"),
                recommendation="Ensure all production traffic uses HTTPS" if not has_https else None,
            ))

    # =========================================================================
    # Input Validation Checks
    # =========================================================================

    def _check_request_size_limits(self) -> None:
        """Check request size limits."""
        middleware_files = list((self.project_root / "services/inference_api/middleware").glob("*.py"))

        has_size_limit = False
        for f in middleware_files:
            try:
                if "content-length" in f.read_text().lower() or "RequestSizeLimit" in f.read_text():
                    has_size_limit = True
                    break
            except:
                pass

        self.report.add_result(CheckResult(
            name="Request Size Limits",
            category="Input Validation",
            passed=has_size_limit,
            severity="medium" if not has_size_limit else "info",
            message="Request size limiting " + ("configured" if has_size_limit else "not found"),
            recommendation="Implement request body size limits (e.g., 1MB)" if not has_size_limit else None,
        ))

    def _check_sql_injection_protection(self) -> None:
        """Check for SQL injection vulnerabilities."""
        # Search for raw SQL patterns
        sql_files = list(self.project_root.glob("**/*.py"))
        vulnerable_patterns = []

        dangerous_patterns = [
            r'execute\s*\(\s*[\'"].*%s',  # String formatting in SQL
            r'execute\s*\(\s*f[\'"]',      # f-string in SQL
            r'\.execute\s*\(\s*[\'"].*\+', # String concatenation in SQL
        ]

        for f in sql_files[:200]:  # Limit search
            try:
                content = f.read_text()
                for pattern in dangerous_patterns:
                    if re.search(pattern, content):
                        vulnerable_patterns.append(str(f.relative_to(self.project_root)))
                        break
            except:
                pass

        if vulnerable_patterns:
            self.report.add_result(CheckResult(
                name="SQL Injection Protection",
                category="Input Validation",
                passed=False,
                severity="critical",
                message=f"Potential SQL injection in {len(vulnerable_patterns)} file(s)",
                details=", ".join(vulnerable_patterns[:5]),
                recommendation="Use parameterized queries instead of string formatting",
            ))
        else:
            self.report.add_result(CheckResult(
                name="SQL Injection Protection",
                category="Input Validation",
                passed=True,
                severity="info",
                message="No obvious SQL injection patterns found",
            ))

    def _check_command_injection_protection(self) -> None:
        """Check for command injection vulnerabilities."""
        python_files = list(self.project_root.glob("**/*.py"))
        vulnerable_files = []

        dangerous_patterns = [
            r'subprocess\..*shell\s*=\s*True',
            r'os\.system\s*\(',
            r'os\.popen\s*\(',
            r'eval\s*\(',
            r'exec\s*\(',
        ]

        for f in python_files[:200]:
            try:
                content = f.read_text()
                for pattern in dangerous_patterns:
                    if re.search(pattern, content):
                        vulnerable_files.append(str(f.relative_to(self.project_root)))
                        break
            except:
                pass

        if vulnerable_files:
            self.report.add_result(CheckResult(
                name="Command Injection Protection",
                category="Input Validation",
                passed=False,
                severity="critical",
                message=f"Potentially dangerous patterns in {len(vulnerable_files)} file(s)",
                details=", ".join(vulnerable_files[:5]),
                recommendation="Avoid shell=True, os.system(), eval(), exec()",
            ))
        else:
            self.report.add_result(CheckResult(
                name="Command Injection Protection",
                category="Input Validation",
                passed=True,
                severity="info",
                message="No command injection patterns found",
            ))

    # =========================================================================
    # Secrets Management Checks
    # =========================================================================

    def _check_env_files(self) -> None:
        """Check for exposed .env files."""
        env_files = list(self.project_root.glob("**/.env"))
        env_files += list(self.project_root.glob("**/.env.*"))

        # Filter out .env.example
        env_files = [f for f in env_files if ".example" not in f.name]

        gitignore = self.project_root / ".gitignore"
        env_ignored = False
        if gitignore.exists():
            env_ignored = ".env" in gitignore.read_text()

        if env_files and not env_ignored:
            self.report.add_result(CheckResult(
                name="Environment Files",
                category="Secrets Management",
                passed=False,
                severity="critical",
                message=f"Found {len(env_files)} .env file(s) not in .gitignore",
                recommendation="Add .env to .gitignore immediately",
            ))
        else:
            self.report.add_result(CheckResult(
                name="Environment Files",
                category="Secrets Management",
                passed=True,
                severity="info",
                message=".env files properly gitignored",
            ))

    def _check_hardcoded_secrets(self) -> None:
        """Check for hardcoded secrets."""
        python_files = list(self.project_root.glob("**/*.py"))
        suspicious_files = []

        secret_patterns = [
            r'password\s*=\s*[\'"][^\'"]{8,}[\'"]',
            r'api_key\s*=\s*[\'"][^\'"]{20,}[\'"]',
            r'secret\s*=\s*[\'"][^\'"]{16,}[\'"]',
            r'token\s*=\s*[\'"][^\'"]{20,}[\'"]',
        ]

        for f in python_files[:200]:
            try:
                content = f.read_text()
                # Skip test files
                if "test" in str(f).lower():
                    continue
                for pattern in secret_patterns:
                    if re.search(pattern, content, re.IGNORECASE):
                        suspicious_files.append(str(f.relative_to(self.project_root)))
                        break
            except:
                pass

        if suspicious_files:
            self.report.add_result(CheckResult(
                name="Hardcoded Secrets",
                category="Secrets Management",
                passed=False,
                severity="critical",
                message=f"Potential hardcoded secrets in {len(suspicious_files)} file(s)",
                details=", ".join(suspicious_files[:5]),
                recommendation="Move secrets to environment variables or secret manager",
            ))
        else:
            self.report.add_result(CheckResult(
                name="Hardcoded Secrets",
                category="Secrets Management",
                passed=True,
                severity="info",
                message="No obvious hardcoded secrets found",
            ))

    def _check_git_history(self) -> None:
        """Check git history for secrets."""
        try:
            # Check if .env was ever committed
            result = subprocess.run(
                ["git", "log", "--all", "--", ".env"],
                capture_output=True,
                text=True,
                cwd=self.project_root,
            )

            if result.stdout.strip():
                self.report.add_result(CheckResult(
                    name="Git History Secrets",
                    category="Secrets Management",
                    passed=False,
                    severity="critical",
                    message=".env file found in git history",
                    recommendation="Use BFG Repo-Cleaner to remove sensitive files from history",
                ))
            else:
                self.report.add_result(CheckResult(
                    name="Git History Secrets",
                    category="Secrets Management",
                    passed=True,
                    severity="info",
                    message="No .env file found in git history",
                ))
        except Exception as e:
            self.log(f"Git history check failed: {e}")

    # =========================================================================
    # API Security Checks
    # =========================================================================

    def _check_swagger_protection(self) -> None:
        """Check if Swagger/ReDoc is protected in production."""
        main_file = self.project_root / "services/inference_api/main.py"

        if main_file.exists():
            content = main_file.read_text()

            # Check for conditional docs
            has_production_check = (
                "ENVIRONMENT" in content and
                ("docs_url=None" in content or "redoc_url=None" in content)
            )

            if has_production_check:
                self.report.add_result(CheckResult(
                    name="API Documentation Protection",
                    category="API Security",
                    passed=True,
                    severity="info",
                    message="Swagger/ReDoc disabled in production",
                ))
            else:
                self.report.add_result(CheckResult(
                    name="API Documentation Protection",
                    category="API Security",
                    passed=False,
                    severity="medium",
                    message="API docs may be exposed in production",
                    recommendation="Disable /docs and /redoc in production",
                ))

    def _check_rate_limiting(self) -> None:
        """Check rate limiting configuration."""
        middleware_files = list((self.project_root / "services/inference_api/middleware").glob("*.py"))

        has_rate_limit = False
        for f in middleware_files:
            try:
                content = f.read_text()
                if "rate" in content.lower() and "limit" in content.lower():
                    has_rate_limit = True
                    break
            except:
                pass

        # Also check main.py
        main_file = self.project_root / "services/inference_api/main.py"
        if main_file.exists():
            if "rate" in main_file.read_text().lower():
                has_rate_limit = True

        self.report.add_result(CheckResult(
            name="Rate Limiting",
            category="API Security",
            passed=has_rate_limit,
            severity="high" if not has_rate_limit else "info",
            message="Rate limiting " + ("configured" if has_rate_limit else "not found"),
            recommendation="Implement rate limiting to prevent abuse" if not has_rate_limit else None,
        ))

    def _check_error_handling(self) -> None:
        """Check error handling doesn't leak sensitive info."""
        # Check for custom exception handlers
        main_file = self.project_root / "services/inference_api/main.py"

        if main_file.exists():
            content = main_file.read_text()
            has_exception_handler = "exception_handler" in content or "setup_exception_handlers" in content

            self.report.add_result(CheckResult(
                name="Error Handling",
                category="API Security",
                passed=has_exception_handler,
                severity="medium" if not has_exception_handler else "info",
                message="Custom error handlers " + ("configured" if has_exception_handler else "not found"),
                recommendation="Implement custom error handlers to prevent stack trace leaks" if not has_exception_handler else None,
            ))

    # =========================================================================
    # Infrastructure Security Checks
    # =========================================================================

    def _check_docker_security(self) -> None:
        """Check Docker security configuration."""
        compose_file = self.project_root / "docker-compose.yml"

        if not compose_file.exists():
            return

        content = compose_file.read_text()

        # Check for resource limits
        has_resource_limits = "resources:" in content and "limits:" in content

        self.report.add_result(CheckResult(
            name="Docker Resource Limits",
            category="Infrastructure",
            passed=has_resource_limits,
            severity="medium" if not has_resource_limits else "info",
            message="Container resource limits " + ("configured" if has_resource_limits else "not found"),
            recommendation="Add CPU/memory limits to all containers" if not has_resource_limits else None,
        ))

        # Check for read-only filesystem
        has_read_only = "read_only: true" in content

        self.report.add_result(CheckResult(
            name="Docker Read-Only Filesystem",
            category="Infrastructure",
            passed=has_read_only,
            severity="low" if not has_read_only else "info",
            message="Read-only filesystem " + ("configured" if has_read_only else "not configured"),
            recommendation="Use read_only: true for containers where possible" if not has_read_only else None,
        ))

    def _check_dependency_vulnerabilities(self) -> None:
        """Check for dependency vulnerability scanning."""
        security_workflow = self.project_root / ".github/workflows/security.yml"

        if security_workflow.exists():
            content = security_workflow.read_text()
            has_scanning = "bandit" in content.lower() or "safety" in content.lower()

            self.report.add_result(CheckResult(
                name="Dependency Vulnerability Scanning",
                category="Infrastructure",
                passed=has_scanning,
                severity="high" if not has_scanning else "info",
                message="Security scanning workflow " + ("configured" if has_scanning else "incomplete"),
            ))
        else:
            self.report.add_result(CheckResult(
                name="Dependency Vulnerability Scanning",
                category="Infrastructure",
                passed=False,
                severity="high",
                message="No security scanning workflow found",
                recommendation="Create .github/workflows/security.yml with Bandit and Safety",
            ))

    # =========================================================================
    # Logging & Monitoring Checks
    # =========================================================================

    def _check_audit_logging(self) -> None:
        """Check audit logging configuration."""
        # Search for audit-related code
        python_files = list(self.project_root.glob("**/*.py"))
        has_audit = False

        for f in python_files[:200]:
            try:
                content = f.read_text()
                if "audit" in content.lower() and "log" in content.lower():
                    has_audit = True
                    break
            except:
                pass

        self.report.add_result(CheckResult(
            name="Audit Logging",
            category="Logging & Monitoring",
            passed=has_audit,
            severity="medium" if not has_audit else "info",
            message="Audit logging " + ("detected" if has_audit else "not found"),
            recommendation="Implement audit logging for security events" if not has_audit else None,
        ))

    def _check_security_monitoring(self) -> None:
        """Check security monitoring configuration."""
        # Check for Prometheus metrics or security monitoring
        prometheus_file = self.project_root / "docker/prometheus/prometheus.yml"

        if prometheus_file.exists():
            self.report.add_result(CheckResult(
                name="Security Monitoring",
                category="Logging & Monitoring",
                passed=True,
                severity="info",
                message="Prometheus monitoring configured",
            ))
        else:
            self.report.add_result(CheckResult(
                name="Security Monitoring",
                category="Logging & Monitoring",
                passed=False,
                severity="medium",
                message="Prometheus monitoring not found",
                recommendation="Configure Prometheus for security metrics collection",
            ))


def print_report(report: PentestReport) -> None:
    """Print the report in a formatted way."""
    print()
    print("=" * 60)
    print("SECURITY CHECKLIST RESULTS")
    print("=" * 60)
    print()
    print(f"Overall Status: {report.overall_status}")
    print(f"Total Checks: {report.total_checks}")
    print(f"  Passed: {report.passed}")
    print(f"  Failed: {report.failed}")
    print(f"  Warnings: {report.warnings}")
    print()

    # Group by category
    categories: Dict[str, List[CheckResult]] = {}
    for r in report.results:
        if r.category not in categories:
            categories[r.category] = []
        categories[r.category].append(r)

    for category, results in categories.items():
        print(f"\n--- {category} ---")
        for r in results:
            status = "[PASS]" if r.passed else "[FAIL]" if r.severity in ('critical', 'high') else "[WARN]"
            severity_marker = f"({r.severity.upper()})" if not r.passed else ""
            print(f"  {status} {r.name} {severity_marker}")
            if not r.passed and r.recommendation:
                print(f"       -> {r.recommendation}")

    print()
    print("=" * 60)

    if report.overall_status == "READY":
        print("System is READY for penetration testing.")
    elif report.overall_status == "CRITICAL_ISSUES":
        print("CRITICAL issues must be fixed before penetration testing!")
    elif report.overall_status == "HIGH_ISSUES":
        print("HIGH severity issues should be addressed before testing.")
    else:
        print("Review findings and address as needed before testing.")

    print("=" * 60)


def main():
    parser = argparse.ArgumentParser(description="Penetration Test Preparation Checklist")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    parser.add_argument("--output", "-o", type=str, help="Output JSON report to file")
    parser.add_argument("--project", "-p", type=str, help="Project root path")
    args = parser.parse_args()

    # Determine project root
    if args.project:
        project_root = Path(args.project)
    else:
        # Try to find project root
        current = Path.cwd()
        while current != current.parent:
            if (current / ".git").exists():
                project_root = current
                break
            current = current.parent
        else:
            project_root = Path.cwd()

    # Run checks
    checker = PentestChecklist(project_root, verbose=args.verbose)
    report = checker.run_all_checks()

    # Print report
    print_report(report)

    # Save JSON report if requested
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(report.to_dict(), f, indent=2)
        print(f"\nReport saved to: {args.output}")

    # Exit with appropriate code
    if report.overall_status in ("CRITICAL_ISSUES", "HIGH_ISSUES"):
        sys.exit(1)
    elif report.overall_status == "ISSUES_FOUND":
        sys.exit(2)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()
